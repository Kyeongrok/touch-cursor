#!/usr/bin/env python3
"""
TouchCursor íƒ€ì´í•‘ ë¡œê·¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python analyze_typing.py <log_file.jsonl>
    python analyze_typing.py --all  # ëª¨ë“  ë¡œê·¸ íŒŒì¼ ë¶„ì„
"""

import json
import pandas as pd
import sys
from pathlib import Path
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows)
try:
    plt.rcParams['font.family'] = 'Malgun Gothic'
    plt.rcParams['axes.unicode_minus'] = False
except:
    pass


def load_jsonl(file_path):
    """JSONL íŒŒì¼ ë¡œë“œ"""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data.append(json.loads(line))
            except:
                continue
    return pd.DataFrame(data)


def analyze_basic_stats(df):
    """ê¸°ë³¸ í†µê³„ ë¶„ì„"""
    print("=" * 60)
    print("ğŸ“Š ê¸°ë³¸ í†µê³„")
    print("=" * 60)

    print(f"ì´ ì´ë²¤íŠ¸ ìˆ˜: {len(df):,}")
    print(f"ì„¸ì…˜ ID: {df['SessionId'].iloc[0] if len(df) > 0 else 'N/A'}")
    print(f"ê¸°ê°„: {df['Timestamp'].min()} ~ {df['Timestamp'].max()}")

    if 'MarkedAsMistake' in df.columns:
        mistake_rate = df['MarkedAsMistake'].mean() * 100
        print(f"\nâŒ ì˜¤íƒ€ìœ¨: {mistake_rate:.2f}% ({df['MarkedAsMistake'].sum():,} / {len(df):,})")

    if 'RolloverDetected' in df.columns:
        rollover_rate = df['RolloverDetected'].mean() * 100
        print(f"âš¡ ë¡¤ì˜¤ë²„ ë°œìƒë¥ : {rollover_rate:.2f}% ({df['RolloverDetected'].sum():,} / {len(df):,})")

    print(f"\nâ±ï¸  íƒ€ì´ë° í†µê³„:")
    print(f"  í‰ê·  ElapsedMs: {df['ElapsedMs'].mean():.2f}ms")
    print(f"  ì¤‘ì•™ê°’ ElapsedMs: {df['ElapsedMs'].median():.2f}ms")
    print(f"  í‘œì¤€í¸ì°¨: {df['ElapsedMs'].std():.2f}ms")

    if 'TimeSinceLastKey' in df.columns:
        print(f"\nâŒ¨ï¸  íƒ€ì´í•‘ ì†ë„:")
        print(f"  í‰ê·  í‚¤ ê°„ê²©: {df['TimeSinceLastKey'].mean():.2f}ms")
        print(f"  ìµœì†Œ í‚¤ ê°„ê²©: {df['TimeSinceLastKey'].min():.2f}ms")
        print(f"  ìµœëŒ€ í‚¤ ê°„ê²©: {df['TimeSinceLastKey'].max():.2f}ms")


def analyze_problem_keys(df):
    """ë¬¸ì œê°€ ë˜ëŠ” í‚¤ ë¶„ì„"""
    print("\n" + "=" * 60)
    print("ğŸ” ë¬¸ì œ í‚¤ ë¶„ì„")
    print("=" * 60)

    # í‚¤ë³„ ë¹ˆë„
    print("\nğŸ“ˆ ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ í‚¤ ì¡°í•© Top 10:")
    key_combos = df['ActivationKeyName'] + ' + ' + df['SourceKeyName']
    top_keys = key_combos.value_counts().head(10)
    for i, (key, count) in enumerate(top_keys.items(), 1):
        print(f"  {i:2d}. {key:20s} : {count:5d}íšŒ")

    # ì˜¤íƒ€ê°€ ìˆëŠ” ê²½ìš°
    if 'MarkedAsMistake' in df.columns and df['MarkedAsMistake'].sum() > 0:
        print("\nâŒ ì˜¤íƒ€ê°€ ë§ì€ í‚¤ Top 10:")
        mistake_keys = df[df['MarkedAsMistake'] == True]
        mistake_combos = mistake_keys['ActivationKeyName'] + ' + ' + mistake_keys['SourceKeyName']
        top_mistakes = mistake_combos.value_counts().head(10)
        for i, (key, count) in enumerate(top_mistakes.items(), 1):
            total = key_combos[key_combos == key].count()
            rate = (count / total * 100) if total > 0 else 0
            print(f"  {i:2d}. {key:20s} : {count:3d}íšŒ / {total:5d}íšŒ = {rate:5.2f}%")


def analyze_timing_patterns(df):
    """íƒ€ì´ë° íŒ¨í„´ ë¶„ì„"""
    print("\n" + "=" * 60)
    print("â±ï¸  íƒ€ì´ë° íŒ¨í„´ ë¶„ì„")
    print("=" * 60)

    if 'MarkedAsMistake' not in df.columns:
        print("ì˜¤íƒ€ ë ˆì´ë¸”ì´ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    mistakes = df[df['MarkedAsMistake'] == True]
    correct = df[df['MarkedAsMistake'] == False]

    if len(mistakes) > 0:
        print(f"\nğŸ“Š ElapsedMs ë¹„êµ:")
        print(f"  ì˜¤íƒ€ í‰ê· : {mistakes['ElapsedMs'].mean():.2f}ms")
        print(f"  ì •ìƒ í‰ê· : {correct['ElapsedMs'].mean():.2f}ms")
        diff = mistakes['ElapsedMs'].mean() - correct['ElapsedMs'].mean()
        print(f"  ì°¨ì´: {diff:+.2f}ms ({'ì˜¤íƒ€ê°€ ë” ë¹ ë¦„' if diff < 0 else 'ì˜¤íƒ€ê°€ ë” ëŠë¦¼'})")

    # ë¡¤ì˜¤ë²„ì™€ ì˜¤íƒ€ì˜ ê´€ê³„
    if 'RolloverDetected' in df.columns:
        print(f"\nâš¡ ë¡¤ì˜¤ë²„ì™€ ì˜¤íƒ€ì˜ ê´€ê³„:")
        rollover_mistakes = df[df['RolloverDetected'] == True]['MarkedAsMistake'].mean() * 100
        normal_mistakes = df[df['RolloverDetected'] == False]['MarkedAsMistake'].mean() * 100
        print(f"  ë¡¤ì˜¤ë²„ ë°œìƒ ì‹œ ì˜¤íƒ€ìœ¨: {rollover_mistakes:.2f}%")
        print(f"  ì •ìƒ ì…ë ¥ ì‹œ ì˜¤íƒ€ìœ¨: {normal_mistakes:.2f}%")


def analyze_key_sequences(df):
    """í‚¤ ì‹œí€€ìŠ¤ íŒ¨í„´ ë¶„ì„"""
    print("\n" + "=" * 60)
    print("ğŸ”— í‚¤ ì‹œí€€ìŠ¤ íŒ¨í„´")
    print("=" * 60)

    if 'PreviousKey' not in df.columns or 'MarkedAsMistake' not in df.columns:
        print("í‚¤ ì‹œí€€ìŠ¤ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì´ì „ í‚¤ â†’ í˜„ì¬ í‚¤ íŒ¨í„´
    df['KeyPair'] = df['PreviousKey'].fillna('(start)') + ' â†’ ' + df['SourceKeyName']

    # ì˜¤íƒ€ìœ¨ì´ ë†’ì€ í‚¤ ì‹œí€€ìŠ¤
    pair_stats = df.groupby('KeyPair').agg({
        'MarkedAsMistake': ['count', 'sum', 'mean']
    }).round(4)
    pair_stats.columns = ['Count', 'Mistakes', 'MistakeRate']
    pair_stats = pair_stats[pair_stats['Count'] >= 5]  # ìµœì†Œ 5íšŒ ì´ìƒ
    pair_stats = pair_stats.sort_values('MistakeRate', ascending=False)

    print("\nâŒ ì˜¤íƒ€ìœ¨ì´ ë†’ì€ í‚¤ ì‹œí€€ìŠ¤ Top 10:")
    for i, (pair, row) in enumerate(pair_stats.head(10).iterrows(), 1):
        print(f"  {i:2d}. {pair:30s} : {row['MistakeRate']*100:5.2f}% ({int(row['Mistakes'])}/{int(row['Count'])})")


def analyze_time_of_day(df):
    """ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„"""
    print("\n" + "=" * 60)
    print("ğŸ• ì‹œê°„ëŒ€ë³„ íŒ¨í„´")
    print("=" * 60)

    df['Timestamp'] = pd.to_datetime(df['Timestamp'])
    df['Hour'] = df['Timestamp'].dt.hour

    hourly = df.groupby('Hour').agg({
        'SourceKeyName': 'count',
        'MarkedAsMistake': 'mean',
        'ElapsedMs': 'mean'
    }).round(2)
    hourly.columns = ['Count', 'MistakeRate', 'AvgElapsedMs']

    print("\nğŸ“… ì‹œê°„ëŒ€ë³„ í†µê³„:")
    print("  ì‹œê° | ì´ë²¤íŠ¸ ìˆ˜ | ì˜¤íƒ€ìœ¨ | í‰ê·  ElapsedMs")
    print("  " + "-" * 50)
    for hour, row in hourly.iterrows():
        print(f"  {hour:02d}ì‹œ | {int(row['Count']):8d} | {row['MistakeRate']*100:5.2f}% | {row['AvgElapsedMs']:6.2f}ms")


def generate_plots(df, output_dir='./plots'):
    """ê·¸ë˜í”„ ìƒì„±"""
    Path(output_dir).mkdir(exist_ok=True)

    # 1. ElapsedMs ë¶„í¬
    plt.figure(figsize=(10, 6))
    if 'MarkedAsMistake' in df.columns:
        mistakes = df[df['MarkedAsMistake'] == True]
        correct = df[df['MarkedAsMistake'] == False]
        plt.hist([correct['ElapsedMs'], mistakes['ElapsedMs']],
                 bins=50, label=['ì •ìƒ', 'ì˜¤íƒ€'], alpha=0.7)
        plt.legend()
    else:
        plt.hist(df['ElapsedMs'], bins=50)
    plt.xlabel('ElapsedMs (í™œì„±í™” í‚¤ í›„ ê²½ê³¼ ì‹œê°„)')
    plt.ylabel('ë¹ˆë„')
    plt.title('ElapsedMs ë¶„í¬')
    plt.savefig(f'{output_dir}/elapsed_distribution.png', dpi=150, bbox_inches='tight')
    print(f"\nğŸ“Š ê·¸ë˜í”„ ì €ì¥: {output_dir}/elapsed_distribution.png")

    # 2. ì‹œê°„ëŒ€ë³„ ì˜¤íƒ€ìœ¨
    if 'MarkedAsMistake' in df.columns:
        df['Timestamp'] = pd.to_datetime(df['Timestamp'])
        df['Hour'] = df['Timestamp'].dt.hour
        hourly_mistakes = df.groupby('Hour')['MarkedAsMistake'].mean() * 100

        plt.figure(figsize=(12, 5))
        hourly_mistakes.plot(kind='bar')
        plt.xlabel('ì‹œê°„')
        plt.ylabel('ì˜¤íƒ€ìœ¨ (%)')
        plt.title('ì‹œê°„ëŒ€ë³„ ì˜¤íƒ€ìœ¨')
        plt.xticks(rotation=0)
        plt.tight_layout()
        plt.savefig(f'{output_dir}/hourly_mistakes.png', dpi=150, bbox_inches='tight')
        print(f"ğŸ“Š ê·¸ë˜í”„ ì €ì¥: {output_dir}/hourly_mistakes.png")


def main():
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python analyze_typing.py <log_file.jsonl>")
        print("        python analyze_typing.py --all")
        sys.exit(1)

    log_file = sys.argv[1]

    # ë¡œê·¸ íŒŒì¼ ë¡œë“œ
    print(f"ğŸ“‚ ë¡œê·¸ íŒŒì¼ ë¡œë“œ ì¤‘: {log_file}")
    df = load_jsonl(log_file)

    if len(df) == 0:
        print("âŒ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    # ë¶„ì„ ì‹¤í–‰
    analyze_basic_stats(df)
    analyze_problem_keys(df)
    analyze_timing_patterns(df)
    analyze_key_sequences(df)
    analyze_time_of_day(df)

    # ê·¸ë˜í”„ ìƒì„±
    try:
        generate_plots(df)
    except Exception as e:
        print(f"\nâš ï¸  ê·¸ë˜í”„ ìƒì„± ì‹¤íŒ¨: {e}")

    print("\n" + "=" * 60)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("=" * 60)


if __name__ == '__main__':
    main()
